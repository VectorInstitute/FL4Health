{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "directed-singles",
   "metadata": {},
   "source": [
    "# **Centralized Training with PyTorch**  \n",
    "\n",
    "This Jupyter Notebook is adapted from [Nickerson J's blog post](https://www.nickersonj.com/posts/pytorch-tabular/) and provides step-by-step guidance on processing tabular data for training a PyTorch model. Following this blog post, we'll use the Titanic dataset (Kaggle competition page) to build a model that predicts which passengers survived the shipwreck. This is a classification problem, where our goal is to predict either 0 (deceased) or 1 (survived) for each passenger. For opening this notebook in Google Colab:\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/VectorInstitute/FL4Health/tree/main/vector-bootcamp-2025/tabular_centralized_training/centralized_training_for_tabular_data.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "## **Workflow Overview**  \n",
    "\n",
    "To enable effective model training, follow these key steps:  \n",
    "\n",
    "0. **Import Modules**\n",
    "1. **Load Data**\n",
    "2. **Feature Engineering** \n",
    "3. **Define Datasets and Dataloaders**  \n",
    "4. **Define Model**  \n",
    "5. **Train and Save the Model**  \n",
    "6. **Inference**  \n",
    "\n",
    "Each step is essential for preparing your tabular dataset and optimizing the training process. Let's dive in!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-murray",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beginning-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Settings for matplotlib\n",
    "%matplotlib inline\n",
    "mpl.rc(\"axes\", labelsize=14)\n",
    "mpl.rc(\"xtick\", labelsize=12)\n",
    "mpl.rc(\"ytick\", labelsize=12)\n",
    "\n",
    "# Specify float format for pandas tables\n",
    "pd.options.display.float_format = \"{:.3f}\".format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-bubble",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We should first load data and the separate label column from training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "multiple-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sought-comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reported-settle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.283</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.100</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex    Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male 22.000      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female 38.000      1   \n",
       "2                             Heikkinen, Miss. Laina  female 26.000      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female 35.000      1   \n",
       "4                           Allen, Mr. William Henry    male 35.000      0   \n",
       "\n",
       "   Parch            Ticket   Fare Cabin Embarked  \n",
       "0      0         A/5 21171  7.250   NaN        S  \n",
       "1      0          PC 17599 71.283   C85        C  \n",
       "2      0  STON/O2. 3101282  7.925   NaN        S  \n",
       "3      0            113803 53.100  C123        S  \n",
       "4      0            373450  8.050   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "portable-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training features from label column\n",
    "train_labels = df[\"Survived\"].copy()\n",
    "df = df.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-stocks",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature engineering can take various forms depending on the type of data in each column. For federated learning prototyping, it's generally best to preprocess the data before splitting it across clients. This ensures consistent processing steps and standardization across all clients. However, in real-world scenarios, it's also important to consider the challenges of feature preprocessing when data is already distributed across different clients. In general, we can follow these guidelines:  \n",
    "\n",
    "### **1. Handling Categorical Features**  \n",
    "Categorical variables need to be encoded to be usable in a machine learning model.  \n",
    "**Label Encoding** (for ordinal categories):\n",
    "\n",
    "```python\n",
    "  from sklearn.preprocessing import LabelEncoder\n",
    "  \n",
    "  df['category_encoded'] = LabelEncoder().fit_transform(df['category_column'])\n",
    "```\n",
    "\n",
    "**One-Hot Encoding** (for nominal categories):\n",
    "\n",
    "```python\n",
    "  df = pd.get_dummies(df, columns=['category_column'], drop_first=True)\n",
    "```\n",
    "\n",
    "### **2. Handling Numerical Features**\n",
    "Numerical features may need (not all) transformations to improve model performance.\n",
    "\n",
    "**Log Transformation** (for skewed distributions):\n",
    "\n",
    "```python\n",
    "  df['log_feature'] = df['numerical_feature'].apply(lambda x: np.log1p(x))\n",
    "```\n",
    "\n",
    "**Binning/Discretization** (for grouping continuous values):\n",
    "\n",
    "```python\n",
    "  df['binned_feature'] = pd.cut(df['numerical_feature'], bins=5, labels=False)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### **3. Handling Date Features**\n",
    "Dates should be converted into useful numerical representations.\n",
    "\n",
    "**Extracting Date Components**:\n",
    "\n",
    "```python\n",
    "  df['year'] = df['date_column'].dt.year\n",
    "  df['month'] = df['date_column'].dt.month\n",
    "  df['day'] = df['date_column'].dt.day\n",
    "  df['weekday'] = df['date_column'].dt.weekday\n",
    "```\n",
    "\n",
    "**Cyclic Encoding** (for periodic features like months and weekdays):\n",
    "\n",
    "```python\n",
    "  df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "  df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "  df['week_sin'] = np.sin(2 * np.pi * df['week'] / 7)\n",
    "  df['week_cos'] = np.cos(2 * np.pi * df['week'] / 7)\n",
    "```\n",
    "\n",
    "**Compute Time Differences** (useful for Neural Networks):\n",
    "\n",
    "```python\n",
    "  df['days_since_start'] = (df['date'] - df['date'].min()).dt.days\n",
    "  df['time_since_event'] = (df['date'] - df['event_date']).dt.days\n",
    "```\n",
    "\n",
    "### **4. Handling Missing Values**\n",
    "Missing data should be addressed to avoid issues in training.\n",
    "\n",
    "**Fill with Mean/Median** (for numerical data):\n",
    "\n",
    "```python\n",
    "  df['numerical_feature'].fillna(df['numerical_feature'].median(), inplace=True)\n",
    "```\n",
    "\n",
    "**Fill with Mode** (for categorical data):\n",
    "\n",
    "```python\n",
    "  df['category_column'].fillna(df['category_column'].mode()[0], inplace=True)\n",
    "```\n",
    "\n",
    "**Use Indicator Columns for Missing Values**:\n",
    "\n",
    "```python\n",
    "  df['missing_indicator'] = df['numerical_feature'].isna().astype(int)\n",
    "```\n",
    "\n",
    "### **5. Scaling and Normalization**\n",
    "\n",
    "Scaling ensures all features have similar ranges, improving model performance. It is particularly important for numerical columns.\n",
    "\n",
    "**Standardization** (zero mean, unit variance):\n",
    "\n",
    "```python\n",
    "  from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  df[['numerical_feature']] = scaler.fit_transform(df[['numerical_feature']])\n",
    "```\n",
    "\n",
    "**Min-Max Scaling** (scales values between 0 and 1):\n",
    "\n",
    "```python\n",
    "  from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "  scaler = MinMaxScaler()\n",
    "  df[['numerical_feature']] = scaler.fit_transform(df[['numerical_feature']])\n",
    "```\n",
    "### **6. Feature Interaction and Polynomial Features**\n",
    "\n",
    "You can combine existing features to capture non-linear relationships.\n",
    "\n",
    "### **7. Column Dropping**\n",
    "\n",
    "Also you can drop unnecessary column that would not effect training results.\n",
    "\n",
    "Here is a sample feature engineering process applied to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # The Fare column is skewed, so taking the natural log will make it more even\n",
    "    df[\"LogFare\"] = np.log1p(df[\"Fare\"])\n",
    "\n",
    "    # Taking the first character of the Cabin column gives the deck, and mapping single\n",
    "    # characters to groups of decks; other decks will be NaN\n",
    "    df[\"DeckGroup\"] = (\n",
    "        df[\"Cabin\"].str[0].map({\"A\": \"ABC\", \"B\": \"ABC\", \"C\": \"ABC\", \"D\": \"DE\", \"E\": \"DE\", \"F\": \"FG\", \"G\": \"FG\"})\n",
    "    )\n",
    "\n",
    "    # Add up all family members\n",
    "    df[\"Family\"] = df[\"SibSp\"] + df[\"Parch\"]\n",
    "\n",
    "    # If the person traveled alone (=1) or has any family members (=0)\n",
    "    df[\"Alone\"] = (df[\"Family\"] == 0).map({True: 1, False: 0})\n",
    "\n",
    "    # Specify the ticket frequency (how common someone's ticket is)\n",
    "    df[\"TicketFreq\"] = df.groupby(\"Ticket\")[\"Ticket\"].transform(\"count\")\n",
    "\n",
    "    # Extract someone's title (e.g., Mr, Mrs, Miss, Rev)\n",
    "    df[\"Title\"] = df[\"Name\"].str.split(\", \", expand=True).iloc[:, 1].str.split(\".\", expand=True).iloc[:, 0]\n",
    "\n",
    "    # Limit titles to those in the dictionary below; other titles will be NaN\n",
    "    df[\"Title\"] = df[\"Title\"].map({\"Mr\": \"Mr\", \"Miss\": \"Miss\", \"Mrs\": \"Mrs\", \"Master\": \"Master\"})\n",
    "\n",
    "    # Change sex to numbers (male=1, female=0)\n",
    "    df[\"Sex\"] = df[\"Sex\"].map({\"male\": 1, \"female\": 0})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "df = feature_engineering(df)\n",
    "\n",
    "# Remove columns I no longer need\n",
    "df = df.drop([\"Name\", \"Ticket\", \"Cabin\", \"PassengerId\", \"Fare\", \"SibSp\", \"Parch\"], axis=1)\n",
    "\n",
    "# Fill missing values with the modes\n",
    "train_modes = df.mode().iloc[0]\n",
    "\n",
    "\n",
    "def fill_missing(df: pd.DataFrame, modes: pd.Series) -> pd.DataFrame:\n",
    "    df = df.fillna(modes)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = fill_missing(df, train_modes)\n",
    "\n",
    "# Perform min-max scaling\n",
    "def scale_min_max(df: pd.DataFrame, col_name: str, xmin: float, xmax: float) -> pd.DataFrame:\n",
    "    df[col_name] = (df[col_name] - xmin) / (xmax - xmin)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_age_min = df[\"Age\"].min()\n",
    "train_age_max = df[\"Age\"].max()\n",
    "df = scale_min_max(df, \"Age\", train_age_min, train_age_max)\n",
    "\n",
    "# Add dummy variables\n",
    "def add_dummies(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    df = pd.get_dummies(df, columns=cols, dtype=int)\n",
    "    return df\n",
    "\n",
    "\n",
    "cols = [\"Pclass\", \"Embarked\", \"DeckGroup\", \"Title\"]\n",
    "df = add_dummies(df, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "yellow-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same data processing steps to the test data\n",
    "test_proc = (\n",
    "    test_df.pipe(feature_engineering)\n",
    "    .drop([\"Name\", \"Ticket\", \"Cabin\", \"PassengerId\", \"Fare\", \"SibSp\", \"Parch\"], axis=1)\n",
    "    .pipe(fill_missing, train_modes)\n",
    "    .pipe(scale_min_max, \"Age\", train_age_min, train_age_max)\n",
    "    .pipe(add_dummies, cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-institution",
   "metadata": {},
   "source": [
    "## Define Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-sugar",
   "metadata": {},
   "source": [
    "Now, you can convert the DataFrames to tensors while specifying the data type. Additionally, we can split the training data into separate training and validation sets which is useful for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "laughing-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.tensor(df.values, dtype=torch.float32)\n",
    "y_data = torch.tensor(train_labels.values, dtype=torch.float32)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_data, y_data, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "noted-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.tensor(test_proc.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, x: torch.Tensor, y: torch.Tensor = None) -> None:\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        if self.y is None:\n",
    "            # For test dataset\n",
    "            return self.x[idx], None\n",
    "        else:\n",
    "            # For train and validation dataset\n",
    "            return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "swiss-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "train_dataset = TabularDataset(x_train, y_train)\n",
    "validation_dataset = TabularDataset(x_valid, y_valid)\n",
    "test_dataset = TabularDataset(test_proc, None)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "validation_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-catholic",
   "metadata": {},
   "source": [
    "## Define Model and Optimizers\n",
    "\n",
    "After defining dataloader it is time to implement a simple Multi-Layer Perceptron to train over this data. This model can be replaced with more complex and advanced ones, which can be found in:\n",
    "\n",
    "1. TabNet: https://medium.com/@turkishtechnology/deep-learning-with-tabnet-b881236e28c1\n",
    "2. TabTransformer: https://github.com/lucidrains/tab-transformer-pytorch\n",
    "3. TabPFN: https://arxiv.org/pdf/2207.01848\n",
    "4. DANets: https://github.com/WhatAShot/DANet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, num_classes: int = 2) -> None:\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 64)\n",
    "        self.linear2 = nn.Linear(64, 128)\n",
    "        self.linear3 = nn.Linear(128, 96)\n",
    "        self.linear4 = nn.Linear(96, 32)\n",
    "        self.linear5 = nn.Linear(32, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.dropout(self.relu(self.linear1(x)))\n",
    "        x = self.dropout(self.relu(self.linear2(x)))\n",
    "        x = self.dropout(self.relu(self.linear3(x)))\n",
    "        x = self.dropout(self.relu(self.linear4(x)))\n",
    "        output = self.softmax(self.linear5(x))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alike-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the available processor to device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = TitanicModel(19).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-attachment",
   "metadata": {},
   "source": [
    "## Train and Save the Model\n",
    "\n",
    "Now that we’ve defined the two main components required for training the model, we can proceed with the training process. In addition to the model, we also need to define the optimizer, and loss function, as shown below. We also define accuracy function to compute for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "def accuracy_fn(y_true: torch.Tensor, y_pred: torch.Tensor) -> float:\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = correct / len(y_pred) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-while",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train Loss: 0.69017, Accuracy: 61.50% | Validation Loss: 0.68970, Accuracy: 63.91%\n",
      "Epoch:  500 | Train Loss: 0.65902, Accuracy: 63.45% | Validation Loss: 0.65463, Accuracy: 64.38%\n",
      "Epoch: 1000 | Train Loss: 0.65190, Accuracy: 63.91% | Validation Loss: 0.64860, Accuracy: 64.38%\n",
      "Epoch: 1500 | Train Loss: 0.64052, Accuracy: 64.84% | Validation Loss: 0.63982, Accuracy: 64.38%\n",
      "Epoch: 2000 | Train Loss: 0.60310, Accuracy: 66.28% | Validation Loss: 0.59272, Accuracy: 64.84%\n",
      "Epoch: 2500 | Train Loss: 0.52985, Accuracy: 77.66% | Validation Loss: 0.52195, Accuracy: 79.02%\n",
      "Epoch: 3000 | Train Loss: 0.51364, Accuracy: 79.56% | Validation Loss: 0.48616, Accuracy: 82.46%\n",
      "Epoch: 3500 | Train Loss: 0.49338, Accuracy: 81.92% | Validation Loss: 0.47733, Accuracy: 83.11%\n",
      "Epoch: 4000 | Train Loss: 0.49772, Accuracy: 81.19% | Validation Loss: 0.46979, Accuracy: 84.15%\n",
      "Epoch: 4500 | Train Loss: 0.47765, Accuracy: 84.15% | Validation Loss: 0.45647, Accuracy: 84.88%\n",
      "Epoch: 5000 | Train Loss: 0.47948, Accuracy: 83.61% | Validation Loss: 0.46939, Accuracy: 84.39%\n",
      "Epoch: 5500 | Train Loss: 0.47339, Accuracy: 83.28% | Validation Loss: 0.45195, Accuracy: 85.58%\n",
      "Epoch: 6000 | Train Loss: 0.46622, Accuracy: 85.19% | Validation Loss: 0.45393, Accuracy: 86.10%\n",
      "Epoch: 6500 | Train Loss: 0.45803, Accuracy: 85.84% | Validation Loss: 0.46585, Accuracy: 84.84%\n",
      "Epoch: 7000 | Train Loss: 0.46671, Accuracy: 84.21% | Validation Loss: 0.44680, Accuracy: 86.70%\n",
      "Epoch: 7500 | Train Loss: 0.46060, Accuracy: 85.58% | Validation Loss: 0.46391, Accuracy: 84.84%\n",
      "Epoch: 8000 | Train Loss: 0.45691, Accuracy: 85.71% | Validation Loss: 0.45457, Accuracy: 85.77%\n",
      "Epoch: 8500 | Train Loss: 0.46658, Accuracy: 84.39% | Validation Loss: 0.44630, Accuracy: 86.70%\n",
      "Epoch: 9000 | Train Loss: 0.44972, Accuracy: 86.38% | Validation Loss: 0.43962, Accuracy: 87.43%\n",
      "Epoch: 9500 | Train Loss: 0.46986, Accuracy: 83.67% | Validation Loss: 0.45499, Accuracy: 85.77%\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs\n",
    "epochs = 10000\n",
    "\n",
    "\n",
    "# Empty loss lists to track values\n",
    "epoch_count, train_loss_values, valid_loss_values = [], [], []\n",
    "\n",
    "# Loop through the data\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Put the model in training mode\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss: float = 0\n",
    "    total_train_acc: float = 0\n",
    "    num_train_batches: float = 0\n",
    "\n",
    "    for x_train, y_train in train_loader:\n",
    "\n",
    "        # Send data to the device\n",
    "        x_train = x_train.to(device)\n",
    "        y_train = y_train.type(torch.LongTensor).to(device)\n",
    "\n",
    "        # Forward pass to get predictions\n",
    "        y_logits = model(x_train)\n",
    "        # Convert logits into predictions\n",
    "        y_pred = torch.argmax(y_logits, dim=1)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(y_logits, y_train)\n",
    "        # Calculate the accuracy; convert the labels to integers\n",
    "        acc = accuracy_fn(y_train, y_pred)\n",
    "\n",
    "        # Reset the gradients so they don't accumulate each iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass: backpropagate the prediction loss\n",
    "        loss.backward()\n",
    "        # Gradient descent: adjust the parameters by the gradients collected in the backward pass\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and accuracy\n",
    "        total_train_loss += loss.item()\n",
    "        total_train_acc += acc\n",
    "        num_train_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_train_batches\n",
    "    avg_train_acc = total_train_acc / num_train_batches\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    total_valid_loss: float = 0\n",
    "    total_valid_acc: float = 0\n",
    "    num_valid_batches: float = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for x_valid, y_valid in train_loader:\n",
    "            # Send data to the device\n",
    "            x_valid = x_valid.to(device)\n",
    "            y_valid = y_valid.type(torch.LongTensor).to(device)\n",
    "\n",
    "            valid_logits = model(x_valid)\n",
    "            y_pred = torch.argmax(valid_logits, dim=1)  # convert logits into predictions\n",
    "\n",
    "            valid_loss = loss_fn(valid_logits, y_valid)\n",
    "            valid_acc = accuracy_fn(y_pred, y_valid)\n",
    "\n",
    "            # Accumulate validation loss and accuracy\n",
    "            total_valid_loss += valid_loss.item()\n",
    "            total_valid_acc += valid_acc\n",
    "            num_valid_batches += 1\n",
    "\n",
    "    avg_valid_loss = total_valid_loss / num_valid_batches\n",
    "    avg_valid_acc = total_valid_acc / num_valid_batches\n",
    "\n",
    "    # Print progress a total of 20 times\n",
    "    if epoch % int(epochs / 20) == 0:\n",
    "        print(\n",
    "            f\"Epoch: {epoch:4d} | Train Loss: {avg_train_loss:.5f}, Accuracy: {avg_train_acc:.2f}% | \"\n",
    "            f\"Validation Loss: {avg_valid_loss:.5f}, Accuracy: {avg_valid_acc:.2f}%\"\n",
    "        )\n",
    "        epoch_count.append(epoch)\n",
    "        train_loss_values.append(avg_train_loss)\n",
    "        valid_loss_values.append(avg_valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "parliamentary-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot some of the results\n",
    "plt.plot(epoch_count, train_loss_values, label=\"Training Loss\")\n",
    "plt.plot(epoch_count, valid_loss_values, label=\"Validation Loss\")\n",
    "plt.title(\"Training & Validation Loss Curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "forbidden-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for models\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create a model save path\n",
    "MODEL_NAME = \"pytorch_model.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# Save the model state dict\n",
    "torch.save(obj=model.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-economy",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "With the model trained and saved, we can now predict labels for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "allied-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "all_preds_list = []\n",
    "\n",
    "for x_test, y_test in test_loader:\n",
    "    # Send data to the device\n",
    "    x_test = x_test.to(device)\n",
    "    y_test = y_test.type(torch.LongTensor).to(device)\n",
    "\n",
    "    test_logits = model(x_test)\n",
    "    y_pred = torch.argmax(test_logits, dim=1)  # convert logits into predictions\n",
    "\n",
    "    all_preds_list.append(y_pred.cpu().detach())\n",
    "\n",
    "all_preds = torch.cat(all_preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unauthorized-barrel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "        1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "        1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "        0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SyntheticData",
   "language": "python",
   "name": "synthetic_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
